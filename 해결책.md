좋아요. 방금 올리신 **「Vercel 웹훅 연동 종합 보고서」**를 기준으로 전체 흐름과 구현 세부를 점검해 보니, 큰 방향은 아주 탄탄합니다(서명 검증 → 프로젝트 조회 → Job Lock → 변경 파일만 외과적 처리 → 선택적 AI 분석/릴리즈 노트). 다만 **배포 환경에서의 신뢰성·성능·보안**까지 감안하면 아래 사항들을 꼭 보완해 두는 걸 권합니다. 

---

## ✅ 종합 평가

* **아키텍처**: “변경된 `.md`만 처리(Surgical Update)”와 **Job Lock(RPC)** 로 동시성 제어가 잘 설계되어 있습니다. **핵심 파일 변경 시에만 AI 분석 재실행** 전략도 비용/성능 균형이 좋습니다. 
* **운영/관측**: 세분화된 로그 포인트가 있어 원인 분석이 용이합니다(웹훅 수신→잠금 획득→파일별 처리→해제). 

> 아래 **Must‑Fix(필수)** → **성능/신뢰성 향상** → **운영/가시성** 순으로 제안합니다.

---

## 🛡️ Must‑Fix (보안/정합성)

### 1) **원문(raw body)** 기반 HMAC 검증

보고서의 `verifySignature(payload: string, signature: string)` 예시는 좋지만, 실제 라우트에서 **`req.json()`을 먼저 호출하면 원문이 소모**되어 서명 검증이 무력화될 수 있습니다. **반드시 `await req.text()`로 원문을 읽고** 그 문자열로 HMAC을 계산한 뒤, 통과하면 `JSON.parse(body)`를 사용하세요. (길이 불일치 시 `timingSafeEqual`이 예외를 던지는 점도 처리)

```ts
// app/api/github/webhook/route.ts
export const runtime = 'nodejs'; // raw body & 서비스 키 사용 안전
export const maxDuration = 60;

export async function POST(req: Request) {
  const signature = req.headers.get('x-hub-signature-256') || '';
  const deliveryId = req.headers.get('x-github-delivery') || '';
  const event = req.headers.get('x-github-event') || '';

  const body = await req.text();             // ✅ 1) 원문 확보
  if (!verifySignature(body, signature)) {   // ✅ 2) 원문으로 HMAC 검증
    return new Response('Invalid signature', { status: 401 });
  }
  const payload = JSON.parse(body);          // ✅ 3) 통과 후 파싱
  ...
}
```

> 보고서의 HMAC 검증 예시 자체는 타당합니다. **“raw body로 검증한다”** 는 실행 세부만 반드시 반영해 주세요. 

### 2) **Idempotency 보장(중복 처리 방지)**

GitHub는 동일 Delivery를 **Redeliver**할 수 있습니다. `X‑GitHub‑Delivery`를 **유니크 키로 저장**하고 **이미 처리한 delivery면 즉시 200 OK**로 반환하세요.

```sql
-- idempotency 저장소
CREATE TABLE IF NOT EXISTS vibememory.webhook_deliveries (
  delivery_id text PRIMARY KEY,
  event text not null,
  received_at timestamptz default now(),
  processed_at timestamptz
);
```

```ts
// 처리 전 중복 확인
const exists = await supabaseAdmin
  .from('webhook_deliveries').select('delivery_id').eq('delivery_id', deliveryId).maybeSingle();
if (!exists.data) {
  await supabaseAdmin.from('webhook_deliveries').insert({ delivery_id: deliveryId, event });
} else {
  return new Response('duplicate delivery', { status: 200 });
}
```

### 3) **브랜치 필터링**

기본 브랜치가 아닐 때는 처리하지 않거나(옵션), 별도 큐로 분기하세요. Push payload의 `ref`(예: `refs/heads/main`)로 걸러 **불필요한 인덱싱을 방지**합니다. 

---

## ⚙️ 신뢰성/성능 향상

### 4) **Webhook는 “빠른 ACK + 비동기 처리”**

Serverless 제약(10~60s)과 부하 스파이크를 고려해, 웹훅 엔드포인트에서는 **잠금/중복만 확인하고 200 OK로 즉시 응답**한 뒤, **작업 큐 테이블**에 잡을 넣고 **별도 워커(크론/백그라운드)** 가 실행하는 구조가 안정적입니다.

```sql
CREATE TABLE vibememory.webhook_jobs (
  id uuid primary key default gen_random_uuid(),
  delivery_id text not null unique,
  project_id uuid not null,
  payload jsonb not null,
  status text not null default 'pending', -- pending|running|done|error
  created_at timestamptz default now(),
  updated_at timestamptz default now()
);
```

* **엔드포인트**: 웹훅 수신 → `webhook_jobs`에 upsert → **즉시 200**
* **워커**: Vercel Cron(예: 1분) 또는 **수동 트리거** `/api/cron/process-webhook-jobs` → `pending` 잡 N개를 잡고 처리 → 실패 시 재시도/백오프
* 기존 보고서의 **Job Lock RPC** 는 워커에서 그대로 사용하세요(중복 동시 처리 방지). 

### 5) **GitHub API 재시도/스로틀링**

Octokit에 **throttle 플러그인**을 붙이거나 429/5xx에 대해 **지수 백오프 재시도**를 넣어주세요. Commit 폭주 시에도 안전합니다. (보고서의 “트러블슈팅/재시도” 섹션 강화 권장) 

### 6) **파일 세트 계산 정확도**

`push` payload의 `added/modified/removed`를 합치되, **중복/순서**를 일괄 정리하고, 큰 push의 경우 **Git Compare API**(`/compare/{base}...{head}`)로 **최종 변경 파일**을 재확인하면 드물게 발생하는 누락/중복을 줄일 수 있습니다. 

### 7) **RAG “is_current=false” 후 청크 정리 배치**

현 설계처럼 수정 시 **is_current=false 마킹**은 안전합니다. 다만 누적되면 벡터 인덱스가 커질 수 있어 **야간 배치로 old 청크 purge**(또는 아카이브) 정책을 권합니다. (보고서의 크론 섹션에 “청크 정리” 항목 추가 권장) 

---

## 🔍 운영/관측 품질

### 8) **상관관계 ID(Log Correlation)**

각 요청에 `deliveryId`, `projectId`, `jobId`를 **모든 로그 라인에 주입**하세요. 배포에서 원인 추적 속도가 급격히 빨라집니다. 보고서의 예제 로그에 키를 더해 두면 좋습니다. 

### 9) **에러 표준화 & 상태 전파**

* 처리 실패 시 `webhook_jobs.status='error'`, `error_json` 저장 → 대시보드 “최근 웹훅 상태” 위젯에서 확인
* GitHub **Recent Deliveries**에도 `200 OK`를 주되, 내부 잡 실패는 별도 재시도 경로로 복구

### 10) **권한/비밀키 관리**

* Service Role Key는 **서버 전용(Node 런타임)** 에서만 사용
* 보고서의 **환경 변수 표** 매우 좋습니다. 여기에 “환경별(Dev/Prod) 프로젝트 ID 혼선” 체크리스트를 추가해 배포 오염을 방지하세요. 

---

## 🧩 코드/SQL 패치 제안 요약

1. **raw body HMAC + JSON 파싱 분리**(상단 코드 참고)
2. **Idempotency 테이블**(SQL 위) + 빠른 ACK + 잡 큐 처리
3. **Job Worker 라우트**

```ts
// app/api/cron/process-webhook-jobs/route.ts
export const runtime = 'nodejs';
export const maxDuration = 60;

export async function GET() {
  // pending 잡 N개 fetch → claim_job RPC → 파일 처리 → done/error 업데이트
  // 처리 중/후에도 webhook_deliveries.processed_at 세팅
  return new Response(JSON.stringify({ ok: true }));
}
```

4. **브랜치 필터**

```ts
if (payload.ref !== 'refs/heads/main') {
  return new Response('skip non-default branch', { status: 200 });
}
```

5. **GitHub API 재시도 래퍼**

```ts
async function withRetry<T>(fn: () => Promise<T>, max=3) { ... }
```

---

## (보너스) GPT‑5 스트리밍과의 연결 고도화

* 웹훅이 **핵심 파일 변경**을 감지하면, 챗봇의 **요약 캐시**를 무효화하고 다음 호출에서 새 컨텍스트를 프롬프트에 반영하세요.
* 배포에서 GPT‑5 빈 응답이 나오는 문제는 **모델/파라미터/스트림 소비** 이슈가 결합될 수 있으니, 지난 마이그레이션 가이드의 **`max_completion_tokens` 제거** 및 **스트림 미소비(onText만 사용)** 원칙을 유지하세요.  

---

## 최종 체크리스트

* [ ] `req.text()`로 서명 검증 → 통과 후 `JSON.parse` (raw body 보존) 
* [ ] `X‑GitHub‑Delivery` **유니크 저장 + 중복일 경우 즉시 200** 
* [ ] **빠른 ACK + 잡 큐**(Vercel Cron/수동 워커)로 긴 작업 분리 
* [ ] 기본 브랜치 필터, Compare API로 변경 파일 재검증 
* [ ] 야간 배치로 **old 청크 정리**(is_current=false) 
* [ ] 상관관계 ID 로깅(Delivery/Project/Job) & 에러 표준화 
* [ ] GPT‑5 호출부는 `max_completion_tokens` 미사용, 스트림 미소비(온텍스트 카운트만) 유지  

---

필요하시면 **웹훅 라우트의 실제 패치 파일**(raw‑body 검증/빠른 ACK/잡 큐/브랜치 필터 포함)과 **잡 워커 라우트**까지 붙여서 드리겠습니다. 지금 보고서의 구조만 유지해도 위 보완점들을 얹기 쉬운 형태라, 빠르게 안정화될 겁니다.
