원인 명확합니다. 지금 워커가 **`public.webhook_jobs`** 를 찾고 있는데, 테이블이 **없거나(미생성)** 혹은 **다른 스키마(vibememory)로 만들 계획이었는데 기본 스키마가 `public`으로 고정되어 조회**해서 **PostgREST PGRST205**가 터진 겁니다. 예전에 `job_locks`에서도 같은 유형의 오류가 있었고, “스키마 불일치 → PGRST205”는 Supabase에서 흔한 패턴입니다. 해결책은 **① 스키마를 일치**시키거나 **② 클라이언트에서 스키마를 명시**하는 것입니다. (보고서에도 “job_locks는 `vibememory` 스키마, 직접 테이블 접근 금지, RPC/스키마 명시 사용”이 정리되어 있습니다. 그대로 재현된 상황이에요.) 

아래 **가장 빠른 수정 세트**로 바로 고칩니다.

---

## ✅ 결론 요약(해야 할 일)

1. **테이블을 만들 스키마를 확정**: `vibememory.webhook_jobs` 권장.
2. **워커에서 Supabase 스키마를 명시**해서 조회/갱신:

   * `createClient(..., { db: { schema: 'vibememory' } })` 또는
   * `supabaseAdmin.schema('vibememory').from('webhook_jobs')...`
3. (권장) **멱등성 테이블**(`webhook_deliveries`)과 **클레임 RPC**로 경합 방지.
4. **CRON 보안**: `CRON_SECRET` 설정하고 워커에서 검증(현재 dev 허용 로그가 떠 있음).

---

## 1) 마이그레이션(SQL) — `vibememory.webhook_jobs`

> 이미 `vibememory` 스키마를 쓰고 있으니(예: `job_locks`) 동일 스키마를 권장합니다. 

```sql
-- 스키마 보장
create schema if not exists vibememory;

-- 멱등성(중복 딜리버리 방지) 테이블도 함께 권장
create table if not exists vibememory.webhook_deliveries (
  delivery_id text primary key,
  project_id uuid not null references vibememory.projects(id) on delete cascade,
  event text not null,
  received_at timestamptz default now()
);

-- 잡 큐 테이블
create table if not exists vibememory.webhook_jobs (
  id uuid primary key default gen_random_uuid(),
  delivery_id text unique not null,
  project_id uuid not null references vibememory.projects(id) on delete cascade,
  payload jsonb not null,
  status text not null default 'pending',  -- pending | running | done | error
  tries int not null default 0,
  last_error text,
  created_at timestamptz default now(),
  updated_at timestamptz default now()
);

create index if not exists idx_webhook_jobs_status_created
  on vibememory.webhook_jobs(status, created_at);
```

> 이 테이블은 서버(서비스 롤)에서만 쓰이므로 **RLS 비활성(기본)** 로 두는 게 단순합니다. 클라이언트에서 접근할 일이 없다면 정책 추가 불필요.

---

## 2) 워커 코드 패치 — **스키마 지정이 핵심**

현재 에러 메시지는 PostgREST가 “`public.webhook_jobs`를 못 찾는다”고 말합니다. Supabase JS는 기본 스키마가 `public`이므로, **스키마를 명시적으로 바꿔야 합니다.**

### 옵션 A(전역 기본 스키마 지정)

```ts
// app/api/cron/process-webhook-jobs/route.ts
import { createClient } from '@supabase/supabase-js';

const supabaseAdmin = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!,
  { db: { schema: 'vibememory' } }      // ✅ 기본 스키마를 vibememory로
);

// 이후부터는 .from('webhook_jobs') 그대로 사용 가능
const { data: jobs, error } = await supabaseAdmin
  .from('webhook_jobs')
  .select('*')
  .eq('status', 'pending')
  .order('created_at', { ascending: true })
  .limit(10);
```

### 옵션 B(체이닝으로 스키마 지정)

```ts
const { data: jobs, error } = await supabaseAdmin
  .schema('vibememory')                 // ✅ 이 라인 추가
  .from('webhook_jobs')
  .select('*')
  .eq('status','pending')
  .order('created_at', { ascending: true })
  .limit(10);
```

> `job_locks` 때와 동일한 원리입니다. *“테이블은 `vibememory`에 있고, JS 클라이언트는 기본 `public`을 본다 → PGRST205”*였죠. 보고서에도 “직접 테이블 접근 말고 RPC/스키마 지정” 권고가 기록돼 있습니다. 

---

## 3) 동시성/중복 안전: **클레임 RPC**(권장)

여러 워커가 동시에 잡을 잡아도 안전하게 하려면 DB에서 **원자적 클레임**이 필요합니다(행 락 + `skip locked`). `job_locks`와 동일 컨셉으로 함수 하나 두면 운영이 편해집니다. 

```sql
-- vibememory.claim_webhook_jobs: pending 잡을 p_limit개 running으로 전환하며 반환
create or replace function vibememory.claim_webhook_jobs(p_limit int default 10)
returns setof vibememory.webhook_jobs
language sql
security definer
as $$
  with cte as (
    select id
    from vibememory.webhook_jobs
    where status = 'pending'
    order by created_at asc
    limit p_limit
    for update skip locked
  )
  update vibememory.webhook_jobs j
  set status='running', tries=j.tries+1, updated_at=now()
  where j.id in (select id from cte)
  returning j.*;
$$;
```

워커에서:

```ts
// pending → running으로 클레임
const { data: jobs, error } = await supabaseAdmin
  .rpc('vibememory.claim_webhook_jobs', { p_limit: 10 }); // ✅ 스키마+함수명 전체

// 각 job 처리 후 성공/실패 마킹
await supabaseAdmin.schema('vibememory').from('webhook_jobs')
  .update({ status: 'done', updated_at: new Date().toISOString() })
  .eq('id', job.id);
// 실패 시: { status:'error', last_error: ..., updated_at: ... }
```

> 이전 보고서에서 **“락은 RPC로”** 라는 원칙을 잘 쓰셨습니다. **큐 클레임도 같은 방식**이면 운영 품질이 올라갑니다. 

---

## 4) 보안: CRON 차단

로그에 보면 `scan-worker`가 **“CRON_SECRET not set, allowing request (development mode)”**로 열려 있습니다. 배포에서는 **반드시 비활성**하세요.

```ts
// 공통 헬퍼
function assertCronSecret(req: Request) {
  const header = req.headers.get('x-cron-secret');
  if (!process.env.CRON_SECRET || header !== process.env.CRON_SECRET) {
    return new Response('forbidden', { status: 403 });
  }
}

// 라우트 상단에서 호출
const deny = assertCronSecret(req);
if (deny) return deny;
```

---

## 5) 동작 점검 순서

1. **DDL 적용**: 위 SQL을 Supabase SQL Editor 또는 마이그레이션으로 반영.
2. **워커 패치 배포**: `.schema('vibememory')` 또는 `db.schema` 옵션 적용.
3. **헬스 체크**: `/api/cron/process-webhook-jobs` 호출 →

   * 더 이상 `PGRST205`가 아니어야 함.
   * `pending` 잡이 없으면 200/빈 목록이어야 정상.
4. **웹훅 흐름 점검**: 실제 Push → 웹훅 핸들러가 **잡 생성** → 워커가 **클레임→실행** → `done/error`로 마킹.
5. **보안 확인**: `CRON_SECRET` 설정 후 인증 없는 접근 403.

---

## (참고) 관련 문서와 일치 여부

* **같은 유형의 PGRST205**를 job_locks에서 이미 겪었고, “스키마 불일치 → RPC/스키마 명시”로 해결한 전례가 보고서에 있습니다. 이번도 동일합니다. 
* GPT‑5/배포 문제는 별건이지만, **워커가 잡을 처리해 AI 호출**을 트리거한다면 지난 **GPT‑5 호출 가이드(토큰 상한 제거/모델명 정규화/폴백)** 를 그대로 유지하세요. 배포에서 무응답 방지에 효과적입니다.  

---

## 빠른 체크리스트

* [ ] `vibememory.webhook_jobs` 생성(인덱스 포함) — SQL 반영 완료
* [ ] 워커에서 **`.schema('vibememory')`** 또는 **`{ db: { schema: 'vibememory' } }`** 적용
* [ ] (권장) `vibememory.claim_webhook_jobs()` RPC로 클레임 처리
* [ ] `CRON_SECRET` 설정 및 라우트에서 검증
* [ ] End‑to‑End: Push → 잡 생성 → 워커 처리 → 상태 `done/error` 정상 전환

위 작업대로 반영하면 지금의 **PGRST205 500**은 사라지고, 큐 워커가 안정적으로 돌아갈 겁니다. 필요하시면 **마이그레이션 파일 이름/경로 규약**과 **워커 라우트 전체 패치본**을 현재 레포 구조에 맞춰 바로 정리해 드릴게요.
