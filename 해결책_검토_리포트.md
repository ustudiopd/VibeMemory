# í•´ê²°ì±….md ê²€í†  ë¦¬í¬íŠ¸

**ê²€í†  ì¼ì‹œ**: 2025-01-XX  
**ê²€í†  ëŒ€ìƒ**: `í•´ê²°ì±….md` ê¶Œì¥ì‚¬í•­ vs í˜„ì¬ ì½”ë“œë² ì´ìŠ¤

---

## ğŸ“Š ì „ì²´ ìš”ì•½

| í•­ëª© | ê¶Œì¥ì‚¬í•­ | í˜„ì¬ ìƒíƒœ | ìš°ì„ ìˆœìœ„ |
|------|---------|----------|---------|
| Edge ëŸ°íƒ€ì„ ì„¤ì • | âœ… í•„ìˆ˜ | âŒ ì—†ìŒ | ğŸ”´ ê¸´ê¸‰ |
| maxDuration ì„¤ì • | âœ… í•„ìˆ˜ | âŒ ì—†ìŒ | ğŸ”´ ê¸´ê¸‰ |
| Reasoning ëª¨ë¸ ë¶„ê¸° | âœ… í•„ìˆ˜ | âŒ ì—†ìŒ | ğŸ”´ ê¸´ê¸‰ |
| ëª¨ë¸ëª… ì •ê·œí™” | âœ… ê¶Œì¥ | âŒ ì—†ìŒ | ğŸŸ¡ ì¤‘ìš” |
| ë¹ˆ ìŠ¤íŠ¸ë¦¼ í´ë°± | âœ… ê¶Œì¥ | âš ï¸ ë¶€ë¶„ì  | ğŸŸ¡ ì¤‘ìš” |
| í† í° ìƒí•œ íŒŒë¼ë¯¸í„° | âŒ ê¸ˆì§€ | âœ… ì—†ìŒ | âœ… ì™„ë£Œ |
| ë¡œê¹… ê°œì„  | âœ… ê¶Œì¥ | âœ… ìˆìŒ | âœ… ì™„ë£Œ |

---

## ğŸ”´ ê¸´ê¸‰ ìˆ˜ì • í•„ìš” (Critical)

### 1. Edge ëŸ°íƒ€ì„ ì„¤ì • ëˆ„ë½

**ê¶Œì¥ì‚¬í•­** (`í•´ê²°ì±….md` 1ì¥):
```ts
export const runtime = 'edge';
export const maxDuration = 60;
```

**í˜„ì¬ ìƒíƒœ**:
- `app/api/projects/[id]/chat/route.ts`: âŒ ì—†ìŒ
- `app/api/chat/route.ts`: âŒ ì—†ìŒ
- `app/api/projects/[id]/idea/synthesize/route.ts`: âŒ ì—†ìŒ
- `app/api/projects/[id]/tech-spec/generate/route.ts`: âŒ ì—†ìŒ

**ì˜í–¥**: 
- Vercel ë°°í¬ í™˜ê²½ì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì•ˆì •ì„± ì €í•˜
- ì½œë“œìŠ¤íƒ€íŠ¸ ì§€ì—° ê°€ëŠ¥ì„±
- íƒ€ì„ì•„ì›ƒ ìœ„í—˜ ì¦ê°€

**ìˆ˜ì • í•„ìš” íŒŒì¼**:
- `app/api/projects/[id]/chat/route.ts` (ê°€ì¥ ì¤‘ìš” - ìŠ¤íŠ¸ë¦¬ë° API)
- `app/api/chat/route.ts`
- `app/api/projects/[id]/idea/synthesize/route.ts`
- `app/api/projects/[id]/tech-spec/generate/route.ts`

---

### 2. Reasoning ëª¨ë¸ ë¶„ê¸° ì²˜ë¦¬ ëˆ„ë½

**ê¶Œì¥ì‚¬í•­** (`í•´ê²°ì±….md` 2ì¥):
- Reasoning ëª¨ë¸(`gpt-5*`, `o4*`, `o3*`): `temperature` **ê¸ˆì§€**, í† í° ìƒí•œ **ë¯¸ì§€ì •**
- ì¼ë°˜ ëª¨ë¸(`gpt-4.1-mini`, `gpt-4o-mini`): `temperature`, `maxTokens` ì‚¬ìš© ê°€ëŠ¥

**í˜„ì¬ ìƒíƒœ**:

#### âŒ `app/api/projects/[id]/chat/route.ts` (ë¼ì¸ 285)
```ts
result = await streamText({
  model: openai(MODEL),
  messages: [...],
  temperature: 0.7,  // âŒ reasoning ëª¨ë¸ì—ì„œë„ í•­ìƒ ì ìš©ë¨
});
```

#### âŒ `lib/analysisService.ts` (ë¼ì¸ 221, 253, 297, 344, 372)
```ts
const response = await openai.chat.completions.create({
  model: MODEL,
  messages: [{ role: 'user', content: prompt }],
  temperature: 0.7,  // âŒ reasoning ëª¨ë¸ì—ì„œë„ í•­ìƒ ì ìš©ë¨
});
```

#### âš ï¸ `app/api/projects/[id]/tech-spec/generate/route.ts` (ë¼ì¸ 145)
```ts
const { text: techSpec } = await generateText({
  model: openai(MODEL),
  system: systemPrompt,
  prompt: userPrompt,
  temperature: 0.3,  // âš ï¸ reasoning ëª¨ë¸ì—ì„œë„ ì ìš©ë¨
});
```

#### âœ… `app/api/projects/[id]/idea/synthesize/route.ts` (ë¼ì¸ 168-171)
```ts
const { text: specification } = await generateText({
  model: openai(MODEL),
  prompt: prompt,
  // âœ… temperature ì—†ìŒ (ì¢‹ìŒ)
});
```

**ì˜í–¥**:
- Reasoning ëª¨ë¸ì—ì„œ `temperature` íŒŒë¼ë¯¸í„° ì‚¬ìš© ì‹œ ì˜ˆìƒì¹˜ ëª»í•œ ë™ì‘ ê°€ëŠ¥
- ë¹ˆ ì‘ë‹µ ë°œìƒ ê°€ëŠ¥ì„± ì¦ê°€

**ìˆ˜ì • í•„ìš”**:
```ts
// ê¶Œì¥ íŒ¨í„´
function normalizeModel(raw?: string) {
  return (raw ?? 'gpt-4o-mini').replace(/[\u2010-\u2015\u2212\uFE58\uFE63\uFF0D]/g, '-').trim();
}

const MODEL = normalizeModel(process.env.CHATGPT_MODEL);
const IS_REASONING = /^(gpt-5|o4|o3)/i.test(MODEL);

const opts = IS_REASONING
  ? {}  // reasoning ëª¨ë¸: ì˜µì…˜ ì—†ìŒ
  : { temperature: 0.7, maxTokens: 900 };  // ì¼ë°˜ ëª¨ë¸: ì˜µì…˜ ì‚¬ìš©

await streamText({
  model: openai(MODEL),
  ...opts,
  // ...
});
```

---

## ğŸŸ¡ ì¤‘ìš” ê°œì„  ì‚¬í•­ (High Priority)

### 3. ëª¨ë¸ëª… ì •ê·œí™” ëˆ„ë½

**ê¶Œì¥ì‚¬í•­** (`í•´ê²°ì±….md` 2ì¥, 5ì¥):
- ë¹„ASCII í•˜ì´í”ˆ(â€‘ â€” âˆ’ ë“±)ì„ ASCII '-'ë¡œ í†µì¼
- í™˜ê²½ ë³€ìˆ˜ ë³µë¶™ ì‹œ í•˜ì´í”ˆ í˜¼ì… ë°©ì§€

**í˜„ì¬ ìƒíƒœ**:
```ts
// í˜„ì¬ ì½”ë“œ
const MODEL = process.env.CHATGPT_MODEL || 'gpt-5-mini';
```

**ê¶Œì¥ ì½”ë“œ**:
```ts
function normalizeModel(raw?: string) {
  return (raw ?? 'gpt-4o-mini').replace(/[\u2010-\u2015\u2212\uFE58\uFE63\uFF0D]/g, '-').trim();
}

const MODEL = normalizeModel(process.env.CHATGPT_MODEL);
```

**ì˜í–¥**: 
- í™˜ê²½ ë³€ìˆ˜ì— ë¹„ASCII í•˜ì´í”ˆì´ í¬í•¨ë˜ë©´ ëª¨ë¸ ì¸ì‹ ì‹¤íŒ¨ ê°€ëŠ¥

---

### 4. ë¹ˆ ìŠ¤íŠ¸ë¦¼ í´ë°± ë¡œì§ ë¶€ì¡±

**ê¶Œì¥ì‚¬í•­** (`í•´ê²°ì±….md` 3ì¥):
- ì²­í¬ 0 & ì—ëŸ¬ ì—†ìŒ ì‹œ ê²½ëŸ‰ ëª¨ë¸(`gpt-4o-mini`)ë¡œ 1íšŒ ì¬ì‹œë„

**í˜„ì¬ ìƒíƒœ**:

#### âš ï¸ `app/api/projects/[id]/chat/route.ts` (ë¼ì¸ 335-346)
```ts
// ë¹ˆ ì‘ë‹µ ì²´í¬ë§Œ ìˆê³  í´ë°± ë¡œì§ ì—†ìŒ
if (!fullContent || fullContent.trim().length === 0) {
  console.error('[CHAT] âš ï¸ Empty response from model...');
  const errorEvent = `event: error\ndata: ${JSON.stringify({ 
    error: 'AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤...',
  })}\n\n`;
  controller.enqueue(encoder.encode(errorEvent));
  // âŒ í´ë°± ë¡œì§ ì—†ìŒ
}
```

**ê¶Œì¥ ê°œì„ **:
```ts
// ë¹ˆ ì‘ë‹µ ì‹œ í´ë°± ë¡œì§ ì¶”ê°€
if (!fullContent || fullContent.trim().length === 0) {
  console.warn('[CHAT] Empty stream â†’ fallback to gpt-4o-mini');
  
  // í´ë°±: gpt-4o-minië¡œ ì¬ì‹œë„
  try {
    const fallbackResult = await generateText({
      model: openai('gpt-4o-mini'),
      messages: [
        { role: 'system', content: systemPrompt },
        ...previousMessages,
        { role: 'user', content: userPrompt },
      ],
    });
    
    if (fallbackResult.text) {
      // í´ë°± ì„±ê³µ ì‹œ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì „ì†¡
      const fallbackChunk = `event: token\ndata: ${JSON.stringify(fallbackResult.text)}\n\n`;
      controller.enqueue(encoder.encode(fallbackChunk));
      fullContent = fallbackResult.text;
    }
  } catch (fallbackError) {
    console.error('[CHAT] Fallback also failed:', fallbackError);
    // í´ë°± ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì´ë²¤íŠ¸
    const errorEvent = `event: error\ndata: ${JSON.stringify({ 
      error: 'AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤...',
    })}\n\n`;
    controller.enqueue(encoder.encode(errorEvent));
  }
}
```

**ì˜í–¥**:
- ë¹ˆ ì‘ë‹µ ë°œìƒ ì‹œ ì‚¬ìš©ì ê²½í—˜ ì €í•˜
- ìë™ ë³µêµ¬ ë¶ˆê°€ëŠ¥

---

## âœ… ì˜ êµ¬í˜„ëœ ë¶€ë¶„

### 5. í† í° ìƒí•œ íŒŒë¼ë¯¸í„° ë¯¸ì‚¬ìš© âœ…

**ê¶Œì¥ì‚¬í•­**: Reasoning ëª¨ë¸ì— `max_completion_tokens` ë“± í† í° ìƒí•œ íŒŒë¼ë¯¸í„° ì‚¬ìš© ê¸ˆì§€

**í˜„ì¬ ìƒíƒœ**: âœ… ëª¨ë“  íŒŒì¼ì—ì„œ í† í° ìƒí•œ íŒŒë¼ë¯¸í„° ë¯¸ì‚¬ìš©

---

### 6. ë¡œê¹… ê°œì„  âœ…

**ê¶Œì¥ì‚¬í•­**: ë””ë²„ê¹… ë¡œê¹… ì¶”ê°€

**í˜„ì¬ ìƒíƒœ**: âœ… ìƒì„¸í•œ ë¡œê¹… êµ¬í˜„ë¨
- `[CHAT]` í”„ë¦¬í”½ìŠ¤ë¡œ ë¡œê·¸ êµ¬ë¶„
- ëª¨ë¸ëª…, í”„ë¡¬í”„íŠ¸ ê¸¸ì´, ì²­í¬ ìˆ˜ ë“± ìƒì„¸ ì •ë³´ ë¡œê¹…
- ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ì—ëŸ¬ ì •ë³´ ë¡œê¹…

---

## ğŸ“ ìˆ˜ì • ìš°ì„ ìˆœìœ„ ë° ì‘ì—… ê³„íš

### Phase 1: ê¸´ê¸‰ ìˆ˜ì • (ì¦‰ì‹œ ì ìš©)

1. **Edge ëŸ°íƒ€ì„ + maxDuration ì„¤ì •**
   - `app/api/projects/[id]/chat/route.ts`
   - `app/api/chat/route.ts`
   - `app/api/projects/[id]/idea/synthesize/route.ts`
   - `app/api/projects/[id]/tech-spec/generate/route.ts`

2. **Reasoning ëª¨ë¸ ë¶„ê¸° ì²˜ë¦¬**
   - ëª¨ë¸ëª… ì •ê·œí™” í•¨ìˆ˜ ì¶”ê°€
   - Reasoning ëª¨ë¸ ê°ì§€ ë¡œì§ ì¶”ê°€
   - ì¡°ê±´ë¶€ ì˜µì…˜ ì ìš©

### Phase 2: ì¤‘ìš” ê°œì„  (1-2ì¼ ë‚´)

3. **ë¹ˆ ìŠ¤íŠ¸ë¦¼ í´ë°± ë¡œì§**
   - `app/api/projects/[id]/chat/route.ts`ì— í´ë°± ë¡œì§ ì¶”ê°€
   - `app/api/chat/route.ts`ì— í´ë°± ë¡œì§ ì¶”ê°€

---

## ğŸ” ì¶”ê°€ ê²€í†  ì‚¬í•­

### `lib/analysisService.ts`ì˜ `generateText` ì‚¬ìš©

í˜„ì¬ `lib/analysisService.ts`ëŠ” `openai.chat.completions.create`ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.  
`ai` SDKì˜ `generateText`ë¡œ í†µì¼í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

**ì¥ì **:
- ì¼ê´€ëœ API ì‚¬ìš©
- SDK ë ˆë²¨ì˜ ì—ëŸ¬ í•¸ë“¤ë§
- í–¥í›„ ì—…ë°ì´íŠ¸ ëŒ€ì‘ ìš©ì´

**ë‹¨ì **:
- ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • í•„ìš”
- í…ŒìŠ¤íŠ¸ í•„ìš”

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- `í•´ê²°ì±….md`: Vercelìš© GPT-5 í˜¸ì¶œ ì§€ì¹¨
- `GPT-5-mini_ë§ˆì´ê·¸ë ˆì´ì…˜_ê°€ì´ë“œ.md`: ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ
- `ë¡œì»¬_ë°°í¬_í™˜ê²½_ì°¨ì´_ë¬¸ì œ_ë¦¬í¬íŠ¸.md`: ë¬¸ì œ ë¶„ì„ ë¦¬í¬íŠ¸

---

## âœ… ê²°ë¡ 

**í˜„ì¬ ì½”ë“œëŠ” í•´ê²°ì±….mdì˜ í•µì‹¬ ê¶Œì¥ì‚¬í•­ ì¤‘ 3ê°€ì§€ë¥¼ ëˆ„ë½í•˜ê³  ìˆìŠµë‹ˆë‹¤:**

1. âŒ Edge ëŸ°íƒ€ì„ ì„¤ì • (ê¸´ê¸‰)
2. âŒ Reasoning ëª¨ë¸ ë¶„ê¸° ì²˜ë¦¬ (ê¸´ê¸‰)
3. âš ï¸ ë¹ˆ ìŠ¤íŠ¸ë¦¼ í´ë°± ë¡œì§ (ì¤‘ìš”)

**ì¦‰ì‹œ ìˆ˜ì •ì´ í•„ìš”í•œ í•­ëª©**:
- Edge ëŸ°íƒ€ì„ + maxDuration ì„¤ì •
- Reasoning ëª¨ë¸ ë¶„ê¸° ì²˜ë¦¬ (temperature ì¡°ê±´ë¶€ ì ìš©)

ì´ ë‘ ê°€ì§€ë¥¼ ìˆ˜ì •í•˜ë©´ ë°°í¬ í™˜ê²½ì—ì„œì˜ ì•ˆì •ì„±ì´ í¬ê²Œ ê°œì„ ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.
