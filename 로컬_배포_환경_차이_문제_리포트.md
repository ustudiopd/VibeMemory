# 로컬/배포 환경 차이 문제 리포트

**작성일**: 2025-11-17  
**문제**: GPT-5-mini 모델이 로컬에서는 정상 작동하지만 배포 환경(Vercel)에서는 응답을 생성하지 않음

---

## 📋 문제 개요

### 증상
- **로컬 환경**: GPT-5-mini가 정상적으로 응답 생성 (Content length: 3288, 1679 chunks)
- **배포 환경**: 빈 응답 에러 발생 (`gpt-5-mini에서 출력이 생성되지 않았습니다.`)

### 에러 메시지
```
[ChatInterface] Stream error: {
  error: 'AI가 응답을 생성하지 못했습니다. 잠시 후 다시 시도해주세요.',
  details: 'gpt-5-mini에서 출력이 생성되지 않았습니다.'
}
```

---

## 🔍 로컬 환경 로그 분석

### 정상 작동 로그 (로컬)
```
[CHAT] Calling OpenAI model with: {
  model: 'gpt-5-mini',
  systemPromptLength: 8676,
  userPromptLength: 8554,
  previousMessagesCount: 0,
  totalMessagesCount: 2
}
[CHAT] StreamText result created successfully
[CHAT] Starting to read stream...
[CHAT] First chunk received, length: 1
AI SDK Warning: The "temperature" setting is not supported by this model - temperature is not supported for reasoning models
[CHAT] Stream completed. Total chunks: 1679 Content length: 3288
[CHAT] Usage retrieved: { tokensInput: 0, tokensOutput: 822 }
```

### 관찰 사항
1. ✅ 스트림이 정상적으로 시작됨
2. ✅ 1679개의 청크가 수신됨
3. ✅ 총 3288자의 응답 생성됨
4. ⚠️ `temperature` 파라미터 경고 발생 (하지만 작동함)
5. ⚠️ `tokensInput: 0` - 비정상적 (일반적으로 0이 아님)

---

## 🚨 배포 환경 문제 분석

### 배포 환경 로그 (Vercel)
```
[CHAT] ⚠️ Empty response from GPT-5-mini. No content generated.
```

### 관찰 사항
1. ❌ 스트림이 시작되지 않거나 청크가 수신되지 않음
2. ❌ 빈 응답만 반환됨
3. ❌ 디버깅 로그가 출력되지 않음 (최신 코드가 배포되지 않았을 가능성)

---

## 🔍 가능한 원인 분석

### 1. 환경 변수 차이
**가능성**: 높음

**확인 사항**:
- Vercel 환경 변수에 `CHATGPT_MODEL`이 설정되어 있는지
- 환경 변수 값이 `gpt-5-mini`로 정확히 설정되어 있는지
- 환경 변수 이름의 대소문자 일치 여부

**해결 방법**:
```bash
# Vercel 대시보드에서 확인
Settings → Environment Variables → CHATGPT_MODEL = gpt-5-mini
```

### 2. 코드 배포 지연
**가능성**: 중간

**확인 사항**:
- 최신 코드가 Vercel에 배포되었는지
- `temperature` 파라미터 제거가 반영되었는지
- 디버깅 로그가 출력되는지

**해결 방법**:
- Vercel 배포 로그 확인
- 수동 재배포 시도
- 배포 후 서버 로그에서 `[CHAT] Calling OpenAI model with:` 확인

### 3. API 키 또는 권한 문제
**가능성**: 낮음 (로컬에서 작동하므로)

**확인 사항**:
- Vercel 환경 변수에 `OPENAI_API_KEY`가 설정되어 있는지
- API 키가 유효한지
- API 키에 GPT-5-mini 모델 접근 권한이 있는지

### 4. 타임아웃 또는 리소스 제한
**가능성**: 낮음

**확인 사항**:
- Vercel 함수 실행 시간 제한 (Hobby: 10초, Pro: 60초)
- 로컬에서는 37.7초 소요 (로그 확인)
- Vercel Hobby 플랜 사용 시 타임아웃 가능성

**해결 방법**:
- Vercel Pro 플랜으로 업그레이드
- 프롬프트 길이 단축
- 스트리밍 최적화

### 5. 모델 가용성 문제
**가능성**: 낮음 (로컬에서 작동하므로)

**확인 사항**:
- GPT-5-mini 모델이 특정 리전에서만 사용 가능한지
- Vercel 배포 리전과 모델 가용성 일치 여부

### 6. AI SDK 버전 차이
**가능성**: 낮음

**확인 사항**:
- 로컬과 배포 환경의 `@ai-sdk/openai` 패키지 버전
- `ai` 패키지 버전

---

## ✅ 시도한 해결 방법

### 1. temperature 파라미터 제거
- **상태**: 완료
- **파일**: 
  - `app/api/projects/[id]/chat/route.ts`
  - `app/api/chat/route.ts`
  - `app/api/projects/[id]/tech-spec/generate/route.ts`
- **결과**: 아직 배포되지 않음 (확인 필요)

### 2. 디버깅 로그 추가
- **상태**: 완료
- **추가된 로그**:
  - `[CHAT] Calling OpenAI model with:`
  - `[CHAT] StreamText result created successfully`
  - `[CHAT] First chunk received`
  - `[CHAT] Stream completed`
- **결과**: 배포 환경에서 로그가 출력되지 않음 (코드 미배포 가능성)

### 3. 빈 응답 체크 개선
- **상태**: 완료
- **결과**: 에러 메시지는 표시되지만 근본 원인 해결 안 됨

---

## 🔧 권장 해결 방법

### 즉시 확인 사항 (우선순위 순)

#### 1. Vercel 환경 변수 확인
```bash
# Vercel 대시보드에서 확인
1. Settings → Environment Variables
2. CHATGPT_MODEL = gpt-5-mini 확인
3. OPENAI_API_KEY 확인
4. 환경 변수 재배포 (Redeploy)
```

#### 2. 최신 코드 배포 확인
```bash
# GitHub에서 최신 커밋 확인
git log --oneline -5

# Vercel 배포 로그에서 확인
- 최신 커밋이 배포되었는지
- 빌드가 성공했는지
- 배포 후 서버 로그 확인
```

#### 3. 서버 로그 확인
배포 후 Vercel 서버 로그에서 다음을 확인:
- `[CHAT] Calling OpenAI model with:` 로그 출력 여부
- `[CHAT] StreamText result created successfully` 로그 출력 여부
- `[CHAT] First chunk received` 로그 출력 여부
- 에러 메시지 상세 내용

#### 4. 프롬프트 길이 확인
로컬 로그에서:
- `systemPromptLength: 8676`
- `userPromptLength: 8554`
- 총 약 17KB의 프롬프트

배포 환경에서도 동일한 길이인지 확인 필요.

### 추가 해결 방법

#### 5. 모델 이름 확인
```typescript
// 환경 변수에서 모델 이름 확인
console.log('Model from env:', process.env.CHATGPT_MODEL);
console.log('Model used:', MODEL);
```

#### 6. API 키 권한 확인
- OpenAI 대시보드에서 API 키 권한 확인
- GPT-5-mini 모델 접근 권한 확인

#### 7. 타임아웃 설정 확인
```typescript
// Vercel 함수 타임아웃 설정
export const maxDuration = 60; // Pro 플랜
```

---

## 📊 비교 테이블

| 항목 | 로컬 환경 | 배포 환경 (Vercel) |
|------|----------|-------------------|
| 모델 이름 | `gpt-5-mini` | `gpt-5-mini` (확인 필요) |
| 응답 생성 | ✅ 성공 (3288자) | ❌ 실패 (빈 응답) |
| 청크 수신 | ✅ 1679개 | ❌ 0개 |
| temperature 경고 | ⚠️ 경고 (작동함) | ❓ 확인 불가 |
| 실행 시간 | 37.7초 | ❓ 확인 불가 |
| 디버깅 로그 | ✅ 출력됨 | ❌ 출력 안 됨 |
| 환경 변수 | `.env.local` | Vercel 설정 (확인 필요) |

---

## 🎯 다음 단계

### 1단계: 환경 변수 확인 및 재배포
1. Vercel 대시보드에서 환경 변수 확인
2. `CHATGPT_MODEL=gpt-5-mini` 설정 확인
3. 환경 변수 변경 후 수동 재배포

### 2단계: 최신 코드 배포 확인
1. GitHub에서 최신 커밋 확인
2. Vercel 배포 로그에서 빌드 성공 확인
3. 배포 후 서버 로그 확인

### 3단계: 상세 로그 확인
1. 배포 후 챗봇 테스트
2. Vercel 서버 로그에서 디버깅 로그 확인
3. 에러 메시지 상세 내용 확인

### 4단계: 문제 지속 시
1. 프롬프트 길이 단축 테스트
2. 다른 모델(`gpt-4o-mini`)로 테스트
3. Vercel 함수 타임아웃 설정 확인

---

## 📝 체크리스트

배포 환경 문제 해결을 위한 체크리스트:

- [ ] Vercel 환경 변수 `CHATGPT_MODEL` 확인
- [ ] Vercel 환경 변수 `OPENAI_API_KEY` 확인
- [ ] 최신 코드가 Vercel에 배포되었는지 확인
- [ ] 배포 후 서버 로그에서 디버깅 로그 확인
- [ ] `[CHAT] Calling OpenAI model with:` 로그 출력 확인
- [ ] `[CHAT] StreamText result created successfully` 로그 출력 확인
- [ ] `[CHAT] First chunk received` 로그 출력 확인
- [ ] 프롬프트 길이가 로컬과 동일한지 확인
- [ ] Vercel 함수 타임아웃 설정 확인
- [ ] API 키 권한 확인

---

## 🔗 관련 파일

- `app/api/projects/[id]/chat/route.ts` - 메인 챗봇 API
- `app/api/chat/route.ts` - 일반 챗봇 API
- `app/api/projects/[id]/tech-spec/generate/route.ts` - 기술 스펙 생성 API
- `.env.local` - 로컬 환경 변수
- Vercel 환경 변수 설정

---

## 📚 참고 자료

- [Vercel 환경 변수 설정 가이드](https://vercel.com/docs/concepts/projects/environment-variables)
- [OpenAI API 모델 목록](https://platform.openai.com/docs/models)
- [AI SDK 문서](https://sdk.vercel.ai/docs)

---

**작성자**: AI Assistant  
**최종 업데이트**: 2025-11-17

